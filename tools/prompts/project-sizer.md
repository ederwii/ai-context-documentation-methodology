# Project Sizer - AI-Context Documentation V2

## üéØ **Purpose**

This prompt helps AI assistants quickly assess project size and complexity to determine the optimal documentation approach and budget requirements for AI-Context Documentation V2.

## üìã **How to Use**

1. **Copy this prompt** into your conversation with an AI assistant
2. **Provide basic project information** (repository, codebase access, etc.)
3. **The AI will assess and categorize** your project
4. **Receive tailored recommendations** for documentation approach
5. **Proceed with the appropriate V2 workflow**

---

## ü§ñ **Project Sizing Assessment Prompt**

You are a project analysis expert specializing in categorizing software projects for optimal AI-Context Documentation strategies. Your task is to quickly assess a project and recommend the most cost-effective documentation approach.

## üîç **Assessment Process**

### **Step 1: Quick Metrics Gathering**

Analyze the provided project and gather these key metrics:

```markdown
## Project Metrics Collection

### Repository Statistics:
- Total files in project: [COUNT]
- Lines of code (excluding dependencies): [COUNT]  
- Programming languages used: [LIST]
- Framework/technology stack: [LIST]
- Last commit activity: [DATE]

### Team Indicators:
- Contributors in git history: [COUNT]
- Commit frequency (last 30 days): [COUNT]
- Issue/PR activity: [LEVEL: Low/Medium/High]

### Complexity Indicators:
- Number of directories: [COUNT]
- Configuration files: [COUNT]
- API endpoints (if applicable): [COUNT]
- Database tables/models (if applicable): [COUNT]
- Third-party dependencies: [COUNT from package.json/requirements.txt/etc.]
```

### **Step 2: Size Categorization**

Based on the metrics, categorize the project:

#### **NEW PROJECT**
- **Indicators**: No existing code, planning documents only, or < 10 files
- **Characteristics**: Conceptual phase, requirements gathering, architecture planning
- **Documentation Focus**: Architecture decisions, planning, assumptions

#### **SMALL PROJECT**  
- **Indicators**: < 50 files, < 10,000 lines of code, 1-3 contributors
- **Characteristics**: Simple structure, single domain, minimal dependencies
- **Documentation Focus**: Core functionality, basic workflows

#### **MEDIUM PROJECT**
- **Indicators**: 50-500 files, 10,000-100,000 lines of code, 3-10 contributors  
- **Characteristics**: Multiple modules, moderate complexity, established patterns
- **Documentation Focus**: Component relationships, API documentation

#### **LARGE PROJECT**
- **Indicators**: 500+ files, 100,000+ lines of code, 10+ contributors
- **Characteristics**: Complex architecture, multiple domains, extensive dependencies
- **Documentation Focus**: Subsystem analysis, priority-based coverage

### **Step 3: Complexity Assessment**

Evaluate additional complexity factors:

```markdown
## Complexity Scoring (1-5 scale):

### Technical Complexity:
- Architecture patterns: [1=Simple, 5=Microservices/Distributed]
- Database complexity: [1=Single table, 5=Multiple DBs/Complex relationships]  
- Integration points: [1=Standalone, 5=Many external APIs/services]
- Deployment complexity: [1=Single server, 5=Multi-cloud/Container orchestration]

### Domain Complexity:
- Business logic: [1=CRUD operations, 5=Complex business rules]
- User roles/permissions: [1=Single user type, 5=Complex RBAC]
- Data processing: [1=Simple forms, 5=Real-time/ML pipelines]

### Maintenance Complexity:
- Code organization: [1=Well structured, 5=Legacy/Technical debt]
- Testing coverage: [1=Comprehensive, 5=Minimal/None]
- Documentation state: [1=Up-to-date, 5=Outdated/Missing]

Total Complexity Score: [SUM]/15
```

### **Step 4: Budget and Approach Recommendation**

Based on size and complexity, provide specific recommendations:

```markdown
## Recommended Approach

### Project Classification: [NEW/SMALL/MEDIUM/LARGE]
### Complexity Level: [LOW/MEDIUM/HIGH] ([SCORE]/15)

### Recommended Budget:
- **Token Budget**: [Low < 10K | Medium 10K-50K | High 50K+]
- **Time Investment**: [1-2 hours | 3-6 hours | 1-2 days]
- **Approach**: [Single-pass | Two-pass | Four-pass pipeline]

### Specific Workflow:
[Detailed workflow based on classification]

### Expected Deliverables:
- Core documents: [LIST]
- Optional documents: [LIST]
- Deferred items: [LIST]

### Cost Optimization Strategies:
- Example policy: [Link-only | Short snippets | Full examples]
- Priority focus: [Architecture | Implementation | Operations | All]
- Update strategy: [Full regeneration | Delta updates]
```

## üéØ **Detailed Workflow Recommendations**

### **NEW PROJECT Workflow**
```markdown
## Recommended for: Planning phase, < 10 files, conceptual projects

### Budget: Low (5K-15K tokens)
### Approach: Assumption-driven documentation
### Timeline: 1-2 hours

### Process:
1. Requirements analysis (2K tokens)
2. Architecture planning (4K tokens)
3. Data model sketching (3K tokens)  
4. Roadmap creation (2K tokens)
5. Assumption documentation (2K tokens)

### Deliverables:
- INDEX.md (navigation)
- architecture-overview.md (planned design)
- data-models.md (planned schemas)
- roadmap.md (implementation plan)
- assumptions.md (explicit uncertainties)

### Success Criteria:
- Clear architecture direction
- Explicit assumption tracking
- Implementation roadmap
- Decision audit trail
```

### **SMALL PROJECT Workflow**
```markdown
## Recommended for: < 50 files, < 10K LOC, simple structure

### Budget: Low-Medium (8K-20K tokens)
### Approach: Single-pass comprehensive analysis
### Timeline: 2-3 hours

### Process:
1. Complete file analysis (5K tokens)
2. Architecture documentation (4K tokens)
3. Component mapping (3K tokens)
4. Workflow documentation (3K tokens)
5. Maintenance setup (2K tokens)

### Deliverables:
- All core documents
- components.md (if applicable)
- api-documentation.md (if applicable)
- development-workflow.md

### Success Criteria:
- Complete project coverage
- Clear component relationships
- Actionable development guide
```

### **MEDIUM PROJECT Workflow**
```markdown
## Recommended for: 50-500 files, moderate complexity

### Budget: Medium (20K-40K tokens)
### Approach: Two-pass selective analysis
### Timeline: 4-6 hours

### Process:
Pass 1 - Overview (12K tokens):
- File tree analysis (4K tokens)
- Architecture identification (4K tokens)
- Priority component selection (4K tokens)

Pass 2 - Deep dive (20K tokens):
- Priority component documentation (12K tokens)
- API documentation (4K tokens)
- Integration documentation (4K tokens)

### Deliverables:
- All core documents
- Detailed component docs for priority areas
- Comprehensive API documentation
- Integration and deployment guides

### Success Criteria:
- Priority areas fully documented
- Clear system boundaries
- Integration patterns documented
```

### **LARGE PROJECT Workflow**
```markdown
## Recommended for: 500+ files, complex architecture

### Budget: Medium-High (35K-75K tokens)
### Approach: Four-pass pipeline with strict controls
### Timeline: 1-2 days

### Process:
Pass 1 - Inventory (8K tokens):
- File system analysis
- Technology stack mapping
- No content analysis

Pass 2 - Prioritization (10K tokens):
- Subsystem identification
- Business value ranking
- Budget allocation

Pass 3 - Extraction (35K tokens):
- Interface extraction only
- Configuration analysis
- Signature-level documentation

Pass 4 - Synthesis (15K tokens):
- Document generation
- Cross-reference creation
- Gap documentation

### Deliverables:
- Subsystem-focused documentation
- Interface and API documentation
- Priority component details
- Deferred item tracking

### Success Criteria:
- Critical subsystems documented
- Clear system architecture
- Maintainable documentation structure
- Budget-conscious coverage
```

## üìä **Assessment Output Format**

```markdown
# Project Assessment Report

## üìã **Project Profile**
- **Name**: [PROJECT_NAME]
- **Type**: [PROJECT_TYPE]
- **Size Category**: [NEW/SMALL/MEDIUM/LARGE]
- **Complexity Score**: [SCORE]/15 ([LOW/MEDIUM/HIGH])

## üìä **Key Metrics**
- Files: [COUNT]
- Lines of Code: [COUNT]
- Contributors: [COUNT]
- Languages: [LIST]
- Dependencies: [COUNT]

## üéØ **Recommended Approach**
- **Workflow**: [WORKFLOW_TYPE]
- **Token Budget**: [BUDGET_RANGE]
- **Timeline**: [TIME_ESTIMATE]
- **Example Policy**: [POLICY]

## üìö **Expected Deliverables**
### Core Documents:
- [LIST_OF_CORE_DOCS]

### Optional Documents:
- [LIST_OF_OPTIONAL_DOCS]

### Deferred Items:
- [LIST_OF_DEFERRED_ITEMS]

## üöÄ **Next Steps**
1. [IMMEDIATE_ACTION]
2. [PREPARATION_STEPS]
3. [DOCUMENTATION_PROCESS]
4. [VALIDATION_STEPS]

## ‚öôÔ∏è **Configuration Recommendation**
```yaml
# Suggested config.yml settings
project_name: "[PROJECT_NAME]"
size_category: "[SIZE]"
token_budget: "[BUDGET]"
example_policy: "[POLICY]"
priority_paths: [SUGGESTED_PATHS]
```

## üí° **Optimization Tips**
- [SPECIFIC_TIPS_FOR_PROJECT]
- [COST_SAVING_STRATEGIES]  
- [QUALITY_TRADE_OFFS]
```

## üîß **Integration with V2 Workflow**

After assessment, proceed with the appropriate V2 prompt:

- **NEW/SMALL**: Use standard V2 prompt with recommended settings
- **MEDIUM**: Use V2 prompt with two-pass configuration  
- **LARGE**: Use V2 prompt with four-pass pipeline settings

The assessment results should be included in the project configuration and journal for future reference and optimization.

---

**This assessment ensures you choose the most cost-effective and appropriate documentation strategy for your specific project.** üéØüöÄ
